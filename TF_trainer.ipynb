{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/ashishkrb7/Object-Detection-TF-data-preparation/blob/main/TF_trainer.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/ashishkrb7/Object-Detection-TF-data-preparation/blob/main/TF_trainer.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "</td></table>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "source": [
    "# Integrate Google drive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive'"
   ]
  },
  {
   "source": [
    "# Dependencies installation, environment setup and pull TF API from github"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    " \n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    " \n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib wget\n",
    " \n",
    "!pip install -q pycocotools\n",
    "\n",
    "!python -m pip install -q Cython pandas tf-slim lvis \n",
    "\n",
    "!python -m pip install -q tensorflow-addons\n",
    "\n",
    "!python -m pip install -q tensorflow==1.14\n",
    "\n",
    "import os\n",
    "if not os.path.exists('/content/gdrive/MyDrive/Tensorflow'):os.makedirs('/content/gdrive/MyDrive/Tensorflow')\n",
    "%cd '/content/gdrive/MyDrive/Tensorflow'\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "%cd '/content/gdrive/MyDrive/Tensorflow/models/research'\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "import os\n",
    "# Adding path in environment variable help us to use TF API as library\n",
    "os.environ['PYTHONPATH'] += ':/content/gdrive/MyDrive/Tensorflow/models/research/:/content/gdrive/MyDrive/Tensorflow/models/research/slim/'\n",
    " \n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "source": [
    "# Remove unnecessary files and folder from the directory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil,os\n",
    "# shutil.rmtree(\"/content/gdrive/MyDrive/Tensorflow/models\")\n",
    "# os.remove(\"/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/exporter_main_v2.py\")"
   ]
  },
  {
   "source": [
    "# cd into the TensorFlow directory in your Google Drive and download models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "        TensorFlow\n",
    "        ├───scripts\n",
    "        │   └───preprocessing\n",
    "        │     └───generate_tfrecord.py \n",
    "        │     └───xml_to_csv.py \n",
    "        └───workspace\n",
    "            └───training_demo\n",
    "                ├───annotations\n",
    "                │   └───label_map.pbtxt \n",
    "                ├───exported-models\n",
    "                ├───images\n",
    "                │   ├───test\n",
    "                │   │     └───test images with corresponding XML files (put zip file, code will do rest of the work)\n",
    "                │   └───train\n",
    "                │         └───train images with corresponding XML files (put zip file, code will do rest of the work)\n",
    "                ├───models\n",
    "                │   └───my_ssd_resnet50_v1_fpn\n",
    "                │     └───pipeline.config\n",
    "                └───pre-trained-models\n",
    "                    └───ssd_resnet50_v1_fpn_640x640_coco17_tpu-8"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir_path='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/scripts/preprocessing'):os.makedirs(repo_dir_path+'/Tensorflow/scripts/preprocessing')\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/workspace/training_demo/annotation'):os.makedirs(repo_dir_path+'/Tensorflow/workspace/training_demo/annotation')\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/workspace/training_demo/exported-models'):os.makedirs(repo_dir_path+'/Tensorflow/workspace/training_demo/exported-models')\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/workspace/training_demo/images/train'):os.makedirs(repo_dir_path+'/Tensorflow/workspace/training_demo/images/train')\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/workspace/training_demo/images/test'):os.makedirs(repo_dir_path+'/Tensorflow/workspace/training_demo/images/test')\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/workspace/training_demo/models'):os.makedirs(repo_dir_path+'/Tensorflow/workspace/training_demo/models')\n",
    "if not os.path.exists(repo_dir_path+'/Tensorflow/workspace/training_demo/pre-trained-models'):os.makedirs(repo_dir_path+'/Tensorflow/workspace/training_demo/pre-trained-models')"
   ]
  },
  {
   "source": [
    "# Load files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF-recorder generator\n",
    "import urllib.request\n",
    "url_generate_tfrecord = \"https://raw.githubusercontent.com/ashishkrb7/Object-Detection-TF-data-preparation/main/generate_tfrecord.py\"\n",
    "url_xml_to_csv = \"https://raw.githubusercontent.com/ashishkrb7/Object-Detection-TF-data-preparation/main/xml_to_csv.py\"\n",
    "filename, headers = urllib.request.urlretrieve(url_generate_tfrecord, filename=repo_dir_path+\"/Tensorflow/scripts/preprocessing/generate_tfrecord.py\")\n",
    "filename, headers = urllib.request.urlretrieve(url_xml_to_csv, filename=repo_dir_path+\"/Tensorflow/scripts/preprocessing/xml_to_csv.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test dataset in zip formate to respective folder\n",
    "from google.colab import files\n",
    "%cd {repo_dir_path+'/Tensorflow/workspace/training_demo/images/train'}\n",
    "upload=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip train.zip\n",
    "!rm train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {'/content/gdrive/My Drive/Tensorflow/workspace/training_demo/images/test'}\n",
    "upload=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip test.zip\n",
    "!rm test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "!python gdrive/MyDrive/Tensorflow/scripts/preprocessing/xml_to_csv.py -i gdrive/MyDrive/Tensorflow/workspace/training_demo/images/train -o gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/train_labels.csv -l gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation\n",
    " \n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "!python gdrive/MyDrive/Tensorflow/scripts/preprocessing/xml_to_csv.py -i gdrive/MyDrive/Tensorflow/workspace/training_demo/images/test -o gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/test_labels.csv\n",
    " \n",
    "# Generate `train.record`\n",
    "!python gdrive/MyDrive/Tensorflow/scripts/preprocessing/generate_tfrecord.py --csv_input=gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/train_labels.csv --output_path=gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/train.record --img_path=gdrive/MyDrive/Tensorflow/workspace/training_demo/images/train --label_map gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/label_map.pbtxt\n",
    " \n",
    "# Generate `test.record`\n",
    "!python gdrive/MyDrive/Tensorflow/scripts/preprocessing/generate_tfrecord.py --csv_input=gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/test_labels.csv --output_path=gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/test.record --img_path=gdrive/MyDrive/Tensorflow/workspace/training_demo/images/test --label_map gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/label_map.pbtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record_fname = '/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/test.record'\n",
    "train_record_fname = '/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/train.record'\n",
    "label_map_pbtxt_fname = '/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir='/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/annotation/'\n",
    "%cd {inputDir}\n",
    "!zip -r data.zip {inputDir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('data.zip')"
   ]
  },
  {
   "source": [
    "# Download pre-trained model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To select the model for TF-1 [click here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)\n",
    "\n",
    "Reference:\n",
    "-   [TF1](https://towardsdatascience.com/object-detection-by-tensorflow-1-x-5a8cb72c1c4b)\n",
    "-   [TF2](https://medium.com/swlh/tensorflow-2-object-detection-api-with-google-colab-b2af171e81cc)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='ssd_inception_v2_coco_2018_01_28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(repo_dir_path+f'/Tensorflow/workspace/training_demo/pre-trained-models/{model_name}'):os.makedirs(repo_dir_path+f'/Tensorflow/workspace/training_demo/models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "fname=wget.download(f'http://download.tensorflow.org/models/object_detection/{model_name}.tar.gz')\n",
    "import shutil\n",
    "shutil.unpack_archive(fname,repo_dir_path+'/Tensorflow/workspace/training_demo/pre-trained-models')\n",
    "!rm {fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(repo_dir_path+f'/Tensorflow/workspace/training_demo/pre-trained-models/{model_name}'):os.makedirs(repo_dir_path+f'/Tensorflow/workspace/training_demo/pre-trained-models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pipline.config file. This file need to modify based on dataset\n",
    "shutil.copy(f'./Tensorflow/workspace/training_demo/pre-trained-models/{model_name}/pipeline.config',f'./Tensorflow/workspace/training_demo/models/{model_name}')"
   ]
  },
  {
   "source": [
    "# Configuring a Training Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/Tensorflow/models/research'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "file_resize_height= 800\n",
    "file_resize_width= 600\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "num_steps=1000\n",
    "batch_size=50\n",
    "num_hard_examples= 100\n",
    "fine_tune_checkpoint=f\"/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/pre-trained-models/{model_name}/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFile = \"https://raw.githubusercontent.com/ashishkrb7/Object-Detection-TF-data-preparation/ssd_inception_v2_coco.config\"\n",
    "filename, headers = urllib.request.urlretrieve(configFile, filename=f'/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/models/{model_name}/ssd_inception_v2_coco.config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname1=f'/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/models/{model_name}/pipeline.config'\r\n",
    "pipeline_fname2=f'/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/models/{model_name}/ssd_inception_v2_coco.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pipeline_fname1) as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(pipeline_fname1, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    " \n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    " \n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    " \n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Image height\n",
    "    s = re.sub('height: [0-9]+',\n",
    "               'height: {}'.format(file_resize_height), s)\n",
    "    \n",
    "    # Image width\n",
    "    s = re.sub('width: [0-9]+',\n",
    "               'width: {}'.format(file_resize_width), s)\n",
    "    \n",
    "    # num_hard_examples\n",
    "    s = re.sub('num_hard_examples: [0-9]+',\n",
    "               'num_hard_examples: {}'.format(num_hard_examples), s)   \n",
    "    f.write(s)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pipeline_fname2) as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(pipeline_fname2, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    " \n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    " \n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    " \n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Image height\n",
    "    s = re.sub('height: [0-9]+',\n",
    "               'height: {}'.format(file_resize_height), s)\n",
    "    \n",
    "    # Image width\n",
    "    s = re.sub('width: [0-9]+',\n",
    "               'width: {}'.format(file_resize_width), s)\n",
    "    \n",
    "    # num_hard_examples\n",
    "    s = re.sub('num_hard_examples: [0-9]+',\n",
    "               'num_hard_examples: {}'.format(num_hard_examples), s)   \n",
    "    f.write(s)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {pipeline_fname2}"
   ]
  },
  {
   "source": [
    "# Training setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup verification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/Tensorflow/models/research/slim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py build\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copy('/content/gdrive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf1_test.py','/content/gdrive/MyDrive/Tensorflow/models/research/')\n",
    "shutil.copy('/content/gdrive/MyDrive/Tensorflow/models/research/object_detection/model_main.py','/content/gdrive/MyDrive/Tensorflow/workspace/training_demo')\n",
    "shutil.copy('/content/gdrive/MyDrive/Tensorflow/models/research/object_detection/exporter.py','/content/gdrive/MyDrive/Tensorflow/workspace/training_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/Tensorflow/models/research/'\n",
    "!python model_builder_tf1_test.py\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "print('Done')"
   ]
  },
  {
   "source": [
    "# Start Tensorboard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip uninstall tensorboard-plugin-wit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/Tensorflow/workspace/training_demo'\n",
    "\n",
    "#start the Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=models/{model_name}\n"
   ]
  },
  {
   "source": [
    "# Model training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/gdrive/MyDrive/Tensorflow/workspace/training_demo\n",
    "!python model_main.py --model_dir=/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/models/ssd_inception_v2_coco_2018_01_28 --pipeline_config_path=/content/gdrive/MyDrive/Tensorflow/workspace/training_demo/models/ssd_inception_v2_coco_2018_01_28/ssd_inception_v2_coco.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}